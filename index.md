## Selected projects in data science, machine learning and time-series forecasting

---

### Automated Architecture and Hyperparameter Optimization for Deep Neural Networks Applied in Forecasting the Cross-Section of Stock Returns (Master Thesis)

This project explores the application of deep learning techniques to predict the cross-section of stock returns. The focus is on developing and automatically tuning deep neural network models to enhance the accuracy of stock return forecasts. By leveraging advanced machine learning methodologies, the study aims to assess the predictive performance of semi-automated methodologies in the context of asset pricing.

![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)

<!-- [![](https://img.shields.io/badge/Python-white?logo=Python)](#)  [![](https://img.shields.io/badge/PyTorch-white?logo=pytorch)](#)  -->

<!-- <img src="images/nni_thesis.png?raw=true" /> -->
<img src="images/nni_example.png?raw=true" />


<!-- [View code on GitHub](https://github.com/Antoniodigiovanni/deep-nn-stock-returns) -->
[View the code on GitHub](https://github.com/Antoniodigiovanni/deep-nn-stock-returns)
<br>
[View thesis](pdf/di_giovanni-master_thesis.pdf?raw=true){:target="_blank"}  <!-- The last part allows to open a new tab -->


---

### ObsiChat – AI-Powered Knowledge Assistant

ObsiChat is a full-stack Retrieval-Augmented Generation (RAG) application that empowers users to have natural language conversations with their personal knowledge base. By ingesting and indexing Obsidian notes, it transforms static documentation into a dynamic, queryable intelligence system, allowing for instant retrieval of insights buried within extensive personal archives.

It features a robust pipeline for uploading Obsidian vaults (Zip) or Markdown (md) files, featuring automated metadata extraction and intelligent duplicate detection (SHA-256 hashing).

<!-- Context-Aware RAG Engine: Built on LangChain, it orchestrates semantic search and LLM generation to provide accurate, context-rich answers grounded in user data.
High-Performance Vector Search: Integrates MongoDB Atlas Vector Search for scalable and fast retrieval of relevant document chunks.
Modern Interactive UI: A clean Streamlit frontend providing a seamless chat experience and intuitive document management controls.
Scalable Backend: Powered by FastAPI, ensuring efficient API handling and modular service architecture. -->
<!-- Tech Stack: -->

<!-- Core: Python, LangChain, OpenAI API
Backend: FastAPI, Pydantic
Frontend: Streamlit
Database: MongoDB Atlas (Vector Store) -->


![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)
![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=for-the-badge&logo=fastapi)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=Streamlit&logoColor=white)
![LangChain](https://img.shields.io/badge/LangChain-1C3C3C?style=for-the-badge&logo=langchain&logoColor=white)
![MongoDB](https://img.shields.io/badge/MongoDB-4EA94B?style=for-the-badge&logo=mongodb&logoColor=white)
![OpenAI](https://img.shields.io/badge/OpenAI-412991?style=for-the-badge&logo=openai&logoColor=white)
![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white)
![Pydantic](https://img.shields.io/badge/Pydantic-E92063?style=for-the-badge&logo=pydantic&logoColor=white)
<!-- [![](https://img.shields.io/badge/Python-white?logo=Python)](#) [![](https://img.shields.io/badge/LangChain-ffffff?logo=langchain&logoColor=green)] (#) -->


<img src="images/obsichat.png?raw=true" />

[Try it out!](https://obsichat.streamlit.app/)
[View the code on GitHub](https://github.com/Antoniodigiovanni/obsidian-rag-chat)

---

### Whisper AI Transcriber

A lightweight web application that transcribes YouTube videos, podcasts (via URL), and user-uploaded audio files. It leverages OpenAI’s Whisper model for speech-to-text, supporting both local inference and API-based processing. Built to demonstrate practical integration of AI models in web applications and provide a simple, user-friendly interface for transcription tasks. 

![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![HuggingFace](https://img.shields.io/badge/Hugging%20Face-FFD21E?style=for-the-badge&logo=huggingface&logoColor=black)
<!-- [![](https://img.shields.io/badge/Python-white?logo=Python)](#)  [![](https://img.shields.io/badge/PyTorch-white?logo=pytorch)](#) [![](https://img.shields.io/badge/HuggingFace_Transformers-white?logo=huggingface)](#) -->


<img src="images/whisper-ai-transcriber-short.png?raw=true" />

[View the code on GitHub](https://github.com/Antoniodigiovanni/whisper-ai-transcriber)
<!-- [View code on GitHub](https://github.com/Antoniodigiovanni/whisper-ai-transcriber) -->


---


<!-- ### Project 3


[![](https://img.shields.io/badge/Jupyter-white?logo=Jupyter)](#)
[![](https://img.shields.io/badge/Twitter-white?logo=Twitter)](#)  -->

